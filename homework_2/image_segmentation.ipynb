{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNDL_Homework2\n",
    "\n",
    "After having analysed carefully the code presented in class concerning Image Segmentation, we searched online for a few solutions and we took advantage of the code presented in this GitHub [repository](https://github.com/zhixuhao/unet): an implementation of a U-Net Convolutional Network, inspired in turn by the following [research](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/).\n",
    "\n",
    "We divided our dataset in train and validation using the ImageDataGenerator built-in feature with an 80-20 split.\n",
    "\n",
    "The fixed random seed present in the code makes our results reproducible.\n",
    "\n",
    "We experimented a few data augmentation techniques in order to improve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth\n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                            width_shift_range=10,\n",
    "                                            height_shift_range=10,\n",
    "                                            zoom_range=0.3,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            fill_mode='constant',\n",
    "                                            cval=0,\n",
    "                                            rescale=1./255,\n",
    "                                            validation_split=0.2)\n",
    "    \n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                             width_shift_range=10,\n",
    "                                             height_shift_range=10,\n",
    "                                             zoom_range=0.3,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             fill_mode='constant',\n",
    "                                             cval=0,\n",
    "                                             rescale=1./255,\n",
    "                                             validation_split=0.2)\n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "    train_mask_data_gen = ImageDataGenerator()\n",
    "\n",
    "# Create validation and test ImageDataGenerator objects\n",
    "test_img_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "dataset_dir = '../input/Segmentation_Dataset'\n",
    "\n",
    "# Batch size\n",
    "bs = 4\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "# Training\n",
    "# Two different generators for images and masks\n",
    "# ATTENTION: here the seed is important!! We have to give the same SEED to both the generator\n",
    "# to apply the same transformations/shuffling to images and corresponding masks\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='training')  \n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='training',\n",
    "                                                         color_mode = 'grayscale')\n",
    "\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "# Validation\n",
    "# validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "# list_files (dataset_dir)\n",
    "\n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=False,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='validation')\n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs, \n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=False,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='validation',\n",
    "                                                         color_mode = 'grayscale')\n",
    "\n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)\n",
    "\n",
    "# Test\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "test_img_gen = test_img_data_gen.flow_from_directory(os.path.join(test_dir, 'images'),\n",
    "                                                     target_size=(img_h, img_w),\n",
    "                                                     batch_size=bs, \n",
    "                                                     class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                     shuffle=False,\n",
    "                                                     interpolation='bilinear',\n",
    "                                                     seed=SEED)\n",
    "test_gen = test_img_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# Training\n",
    "# --------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# Test\n",
    "# ----\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n",
    "                                              output_types=(tf.float32, tf.float32),\n",
    "                                              output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "test_dataset = test_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "test_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_IoU(y_true, y_pred):\n",
    "    # from pobability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    # IoU\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "# ------------\n",
    "\n",
    "def create_model(depth, start_f, num_classes, dynamic_input_shape,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics=[my_IoU])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model(depth=4, \n",
    "                     start_f=4, \n",
    "                     num_classes=3, \n",
    "                     dynamic_input_shape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime \n",
    "callbacks = []\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "          epochs=100,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_img_gen),\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps=len(valid_img_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out = model.evaluate(test_dataset,\n",
    "                          steps=len(test_img_gen),\n",
    "                          verbose=0)\n",
    "\n",
    "eval_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "test_img_gen = test_img_data_gen.flow_from_directory(os.path.join(test_dir, 'images'),\n",
    "                                                     target_size=(img_h, img_w),\n",
    "                                                     batch_size=bs, \n",
    "                                                     class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                     shuffle=False,\n",
    "                                                     interpolation='bilinear',\n",
    "                                                     seed=SEED)\n",
    "test_gen = test_img_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(csv_fname, 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(x_):\n",
    "    y_ = tf.cast(x_ > 0.5, tf.int32)\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_gen)\n",
    "preds = prepare_test(preds)\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = test_gen.filenames\n",
    "image_filenames\n",
    "results = {}\n",
    "if True:\n",
    "    for i in range(len(image_filenames)):\n",
    "       results[(image_filenames[i][4:-4])] = rle_encode(preds[i])\n",
    "\n",
    "    create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
